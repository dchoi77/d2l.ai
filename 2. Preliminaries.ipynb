{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1. Data Manipulation\n",
    "\n",
    "## 2.1.5. Saving Memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = tf.constant([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "\n",
    "before = id(Y)\n",
    "Y = 2*Y\n",
    "before == id(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = tf.Variable(tf.zeros_like(Y))\n",
    "before = id(Z)\n",
    "Z.assign(2*Y)\n",
    "before == id(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the @tf.function decorator to wrap computation inside of a TensorFlow graph that gets compiled and optimized before running. This allows TensorFlow to prune unused values, and to re-use prior allocations that are no longer needed. This minimizes the memory overhead of TensorFlow computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.6. Conversion to Other Python Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = Y.numpy()\n",
    "id(B) == id(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensorflow.python.framework.ops.EagerTensor, numpy.ndarray)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Y), type(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3. Linear Algebra\n",
    "\n",
    "## 2.3.6. Reduction    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(4,), dtype=float32, numpy=array([40., 45., 50., 55.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(5,), dtype=float32, numpy=array([ 6., 22., 38., 54., 70.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=190.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=190.0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = tf.reshape(tf.range(20, dtype=tf.float32), (5, 4))\n",
    "\n",
    "tf.reduce_sum(A, 0), tf.reduce_sum(A, 1), tf.reduce_sum(A, [0,1]), tf.reduce_sum(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1), dtype=float32, numpy=\n",
       "array([[ 6.],\n",
       "       [22.],\n",
       "       [38.],\n",
       "       [54.],\n",
       "       [70.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(A, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.7. Dot Products\n",
    "\n",
    "__tf.tensordot()__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=14.0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.range(4, dtype=tf.float32)\n",
    "\n",
    "tf.tensordot(x, x, axes=1)      # inner product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0.],\n",
       "       [0., 1., 2., 3.],\n",
       "       [0., 2., 4., 6.],\n",
       "       [0., 3., 6., 9.]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.tensordot(x, x, axes=0)      # outer product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.8. Matrix-Vector Products\n",
    "\n",
    "__tf.linalg.matvec()__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([ 14.,  38.,  62.,  86., 110.], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.linalg.matvec(A, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.9. Matrix-Matrix Multiplication\n",
    "\n",
    "__tf.matmul()__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
       "array([[ 6.,  6.,  6.],\n",
       "       [22., 22., 22.],\n",
       "       [38., 38., 38.],\n",
       "       [54., 54., 54.],\n",
       "       [70., 70., 70.]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = tf.ones((4, 3), tf.float32)\n",
    "tf.matmul(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4. Calculus\n",
    "\n",
    "## 2.4.3. Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an $n$-dimensional column vector $\\mathbf{x}$ and a function $f:\\mathbb{R}^n\\to\\mathbb{R}$, $\\nabla_{\\mathbf{x}}f(\\mathbf{x}) \\in\\mathbb{R}^n$.\n",
    "\n",
    "* $\\nabla_{\\mathbf{x}}||\\mathbf{x}||^2 = 2 \\mathbf{x}$\n",
    "* $\\nabla_{\\mathbf{x}}\\mathbf{A}\\mathbf{x} = \\mathbf{A}^T$\n",
    "* $\\nabla_{\\mathbf{x}}\\mathbf{x}^T \\mathbf{A} = \\mathbf{A}$\n",
    "* $\\nabla_{\\mathbf{x}}\\mathbf{x}^T \\mathbf{A}\\mathbf{x} = (\\mathbf{A}+\\mathbf{A}^T)\\mathbf{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5. Automatic Differentiation\n",
    "\n",
    "## 2.5.1. A Simple Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 0.,  4.,  8., 12.], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.range(4, dtype=tf.float32)\n",
    "x = tf.Variable(x)                 # x should be a variable\n",
    "\n",
    "# y = 2*(x0**2 + ... + x3**2)\n",
    "# grad(y, x) = 4*x\n",
    "with tf.GradientTape() as t:\n",
    "    y = 2 * tf.tensordot(x, x, axes=1)\n",
    "\n",
    "x_grad = t.gradient(y, x)\n",
    "x_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5.2. Backward for Non-Scalar Variables\n",
    "\n",
    "When we are calling backward on a vector, we are trying to calculate the derivatives of the loss functions for each constituent of a batch of training examples. Here, our intent is not to calculate the differentiation matrix but rather the sum of the partial derivatives computed individually for each example in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 2., 4., 6.], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = (x0**2, ..., x3**2)\n",
    "# grad(y, x) = grad(y0 + ...+ y3, x) = 2*x\n",
    "with tf.GradientTape() as t:\n",
    "    y = x * x\n",
    "t.gradient(y, x)  # Same as `y = tf.reduce_sum(x * x)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5.3. Detaching Computation\n",
    "\n",
    "We have $y = y(x)$ and $z = z(y, x)$.\n",
    "\n",
    "Calculate grad($z$,$x$) treating $y$ as a constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(4,), dtype=bool, numpy=array([ True,  True,  True,  True])>,\n",
       " <tf.Tensor: shape=(4,), dtype=bool, numpy=array([ True,  True,  True,  True])>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set `persistent=True` to run `t.gradient` more than once\n",
    "with tf.GradientTape(persistent=True) as t:\n",
    "    y = x * x\n",
    "    u = tf.stop_gradient(y)\n",
    "    z = u * x\n",
    "\n",
    "t.gradient(z, x) == u, t.gradient(y, x) == 2 * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.6. Probability\n",
    "\n",
    "## 2.6.1. Basic Probability Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=float32, numpy=array([0., 0., 0., 0., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_probs = tf.ones(6) / 6\n",
    "tfp.distributions.Multinomial(1, fair_probs).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 6), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 1., 1., 0.],\n",
       "       [2., 0., 1., 0., 0., 0.],\n",
       "       [1., 1., 1., 0., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfp.distributions.Multinomial([2,3,5], fair_probs).sample()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
